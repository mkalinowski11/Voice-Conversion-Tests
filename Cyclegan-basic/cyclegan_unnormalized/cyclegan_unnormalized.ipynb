{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_4wxub_SjlW",
        "outputId": "1a7fc2d5-e8de-4ac8-d335-feac2ac6dce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from IPython.display import Audio\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1TD8IabTwJM"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAdaFzrUTx3L"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode=\"reflect\"),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=1, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                features[0],\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(Block(in_channels, feature, stride=1 if feature==features[-1] else 2))\n",
        "            in_channels = feature\n",
        "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=(4,4), stride=1, padding=1, padding_mode=\"reflect\"))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        return torch.sigmoid(self.model(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNTaVFpVUDnt",
        "outputId": "6567f293-a2d7-4131-d9e9-c3ea529d3d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 257, 501])\n",
            "torch.Size([1, 30, 60])\n"
          ]
        }
      ],
      "source": [
        "# test\n",
        "discr = Discriminator(1)\n",
        "x = torch.randn(1,1, 257, 501)\n",
        "print(x.shape)\n",
        "x_discr = discr(x)\n",
        "print(x_discr.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIbMIkMsTzYY"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsBKKRnXT2HE"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, use_act, **kwargs):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels,**kwargs),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.ReLU(inplace = True) if use_act else nn.Identity()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class ConvBlockUp(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, **kwargs):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.ReLU(inplace = True)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    self.block = nn.Sequential(\n",
        "        ConvBlock(channels, channels, use_act = True, kernel_size = 3, padding=(1,1)),\n",
        "        ConvBlock(channels, channels, use_act = False, kernel_size = 3, padding=(1,1))\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, channels, num_features = 64, num_residuals = 9):\n",
        "    super().__init__()\n",
        "    self.initial = nn.Sequential(\n",
        "        ConvBlock(in_channels = channels, out_channels = num_features, use_act = True, kernel_size = 7, stride = 1, padding = (3,3), padding_mode = 'reflect')\n",
        "    )\n",
        "    self.down_blocks = nn.ModuleList(\n",
        "        [\n",
        "            ConvBlock(in_channels = num_features, out_channels = 2*num_features, use_act = True, kernel_size = 3, stride = 2, padding = (1,1), padding_mode = \"reflect\"),\n",
        "            ConvBlock(in_channels = 2*num_features, out_channels = 4*num_features, use_act = True, kernel_size = 3, stride = 2, padding = (1,1), padding_mode = \"reflect\")\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    self.res_blocks = nn.Sequential(\n",
        "        *[ResidualBlock(channels = 4*num_features) for _ in range(num_residuals)]\n",
        "    )\n",
        "\n",
        "    self.up_blocks = nn.ModuleList(\n",
        "        [\n",
        "            ConvBlockUp(in_channels = 4*num_features, out_channels = 2*num_features, kernel_size = 3, stride = 2, padding = (1,1)),\n",
        "            ConvBlockUp(in_channels = 2*num_features, out_channels = num_features, kernel_size = 3, stride = 2, padding = (1,1))\n",
        "        ]\n",
        "    )\n",
        "    self.out_layer = nn.Conv2d(in_channels = num_features, out_channels = channels, kernel_size=7, stride=1, padding=(3,3), padding_mode=\"reflect\")\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.initial(x)\n",
        "    for down_block in self.down_blocks:\n",
        "      x = down_block(x)\n",
        "    x = self.res_blocks(x)\n",
        "    for up_block in self.up_blocks:\n",
        "      x = up_block(x)\n",
        "    x = self.out_layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSq7x-PcUOuh",
        "outputId": "ca70f42e-170d-4995-8468-5df8075b4f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 257, 501])\n"
          ]
        }
      ],
      "source": [
        "# generator test\n",
        "generator = Generator(channels=1, num_residuals=9)\n",
        "test_tensor = torch.randn(1,1,257, 501)\n",
        "gen_result = generator(test_tensor)\n",
        "print(gen_result.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw9FYnLaU2aE"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRCPlVfeU4Ji"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, config, filename=\"my_checkpoint.pth\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"current_epoch\": config.CURRENT_EPOCH\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "def load_checkpoint(model, optimizer, config, filename=\"my_checkpoint.pth\"):\n",
        "  checkpoint = torch.load(filename, map_location=config.DEVICE)\n",
        "  model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "  optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "  config.CURRENT_EPOCH = checkpoint[\"current_epoch\"]\n",
        "  for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = config.LEARNING_RATE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-shMXZGyT3EM"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-rTyrh5T4Pj"
      },
      "outputs": [],
      "source": [
        "SAMPLE_RATE = 16000\n",
        "CUTOFF = 64000\n",
        "SPECT_CUTOFF = 501\n",
        "EPS=1e-6\n",
        "RANDOM_SIGNAL_LEVEL_DB = -40.0\n",
        "\n",
        "def preprocess_sound(audio):\n",
        "  audio_stft = librosa.stft(audio, n_fft=512)\n",
        "  amplitude, phase = np.abs(audio_stft), np.angle(audio_stft)\n",
        "  return amplitude, phase\n",
        "\n",
        "def convert_to_complex(amplitude, phase):\n",
        "  return amplitude * np.vectorize(complex)(np.cos(phase), np.sin(phase))\n",
        "\n",
        "def amp_to_decibel(S, ref = 1.0):\n",
        "  return 10 * np.log10( (S)  / ref)\n",
        "\n",
        "def decibel_revert(db):\n",
        "  return 10 ** (db / 10)\n",
        "\n",
        "def signal_pad(signal, fixed_length = CUTOFF, noise_level = RANDOM_SIGNAL_LEVEL_DB):\n",
        "  pad_length = fixed_length - signal.shape[0]\n",
        "  pad = (np.random.rand(pad_length) - 0.5) * 2 * decibel_revert(noise_level)\n",
        "  sound_extended = np.concatenate((signal, pad), axis=0)\n",
        "  return sound_extended\n",
        "\n",
        "def fit_sound(wav, cutoff = CUTOFF):\n",
        "  if wav.shape[0] < cutoff:\n",
        "    signal_padding = signal_pad(wav, fixed_length = cutoff)\n",
        "    return signal_padding\n",
        "  return wav[:cutoff]\n",
        "\n",
        "def complex_to_sound(stft_signal):\n",
        "  return librosa.istft(stft_signal)\n",
        "  \n",
        "class Voice_Dataset(Dataset):\n",
        "    def __init__(self, source_voice_path, target_voice_path):\n",
        "        self.source_voice_path = source_voice_path\n",
        "        self.target_voice_path = target_voice_path\n",
        "\n",
        "        self.source_voices = os.listdir(self.source_voice_path)\n",
        "        self.target_voices = os.listdir(self.target_voice_path)\n",
        "        self.source_voices.sort()\n",
        "        self.target_voices.sort()\n",
        "\n",
        "        self.source_voices_len = len(self.source_voices)\n",
        "        self.target_voices_len = len(self.target_voices)\n",
        "\n",
        "        self.dataset_length = min(self.source_voices_len, self.target_voices_len)\n",
        "        self.ids = [idx for idx in range(self.dataset_length)]\n",
        "        random.shuffle(self.ids)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      sequence_idx = self.ids[index]\n",
        "      src_voice = os.path.join(\n",
        "                                self.source_voice_path,\n",
        "                                self.source_voices[sequence_idx]\n",
        "                                )\n",
        "      target_voice = os.path.join(\n",
        "                                  self.target_voice_path,\n",
        "                                  self.target_voices[sequence_idx]\n",
        "                                  )\n",
        "      src_voice, sr = librosa.load(src_voice, sr = SAMPLE_RATE)\n",
        "      target_voice, sr = librosa.load(target_voice, sr = SAMPLE_RATE)\n",
        "      #\n",
        "      src_voice, target_voice = fit_sound(src_voice), fit_sound(target_voice)\n",
        "      # phase is not required for training\n",
        "      src_voice_amp, _ = preprocess_sound(src_voice)\n",
        "      target_voice_amp, _ = preprocess_sound(target_voice)\n",
        "      #\n",
        "      src_voice_amp = amp_to_decibel(src_voice_amp)\n",
        "      target_voice_amp = amp_to_decibel(target_voice_amp)\n",
        "      # convert to torch\n",
        "      src_voice_amp = torch.from_numpy(src_voice_amp)\n",
        "      target_voice_amp = torch.from_numpy(target_voice_amp)\n",
        "      return src_voice_amp.unsqueeze(0).to(torch.float32), target_voice_amp.unsqueeze(0).to(torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viBrcG38T5OX"
      },
      "source": [
        "# Train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZQb_L2qT7E8"
      },
      "outputs": [],
      "source": [
        "def train_fn(disc_target, disc_source, gen_source_target, gen_target_source, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler, config):\n",
        "    TARGET_REALS = 0\n",
        "    TARGET_FAKES = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (source_voice, target_voice) in enumerate(loop):\n",
        "        source_voice = source_voice.to(config.DEVICE)\n",
        "        target_voice = target_voice.to(config.DEVICE)\n",
        "\n",
        "        # Train Discriminators\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_target_voice = gen_source_target(source_voice)\n",
        "\n",
        "            d_target_voice_real = disc_target(target_voice)\n",
        "            d_target_voice_fake = disc_target(fake_target_voice.detach())\n",
        "\n",
        "            TARGET_REALS += d_target_voice_real.mean().item()\n",
        "            TARGET_FAKES += d_target_voice_fake.mean().item()\n",
        "\n",
        "            d_target_real_loss = mse(d_target_voice_real, torch.ones_like(d_target_voice_real))\n",
        "            d_target_fake_loss = mse(d_target_voice_fake, torch.zeros_like(d_target_voice_fake))\n",
        "            d_target_loss = d_target_real_loss + d_target_fake_loss\n",
        "\n",
        "            fake_source_voice = gen_target_source(target_voice)\n",
        "\n",
        "            d_src_real = disc_source(source_voice)\n",
        "            d_src_fake = disc_source(fake_source_voice.detach())\n",
        "\n",
        "            d_source_real_loss = mse(d_src_real, torch.ones_like(d_src_real))\n",
        "            d_source_fake_loss = mse(d_src_fake, torch.zeros_like(d_src_fake))\n",
        "            d_source_loss = d_source_real_loss + d_source_fake_loss\n",
        "\n",
        "            D_loss = (d_target_loss + d_source_loss)/2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "        # Train Generators\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            d_target_fake = disc_target(fake_target_voice)\n",
        "            d_source_fake = disc_source(fake_source_voice)\n",
        "\n",
        "            loss_g_target = mse(d_target_fake, torch.ones_like(d_target_fake))\n",
        "            loss_g_source = mse(d_source_fake, torch.ones_like(d_source_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_source = gen_target_source(fake_target_voice)\n",
        "            cycle_target = gen_source_target(fake_source_voice)\n",
        "            cycle_source_loss = l1(source_voice, cycle_source)\n",
        "            cycle_target_loss = l1(target_voice, cycle_target)\n",
        "\n",
        "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
        "            identity_source = gen_target_source(source_voice)\n",
        "            identity_target = gen_source_target(target_voice)\n",
        "            identity_source_loss = l1(source_voice, identity_source)\n",
        "            identity_target_loss = l1(target_voice, identity_target)\n",
        "\n",
        "            G_loss = (\n",
        "                loss_g_target\n",
        "                + loss_g_source\n",
        "                + cycle_source_loss * config.LAMBDA_CYCLE\n",
        "                + cycle_target_loss * config.LAMBDA_CYCLE\n",
        "                + identity_source_loss * config.LAMBDA_IDENTITY\n",
        "                + identity_target_loss * config.LAMBDA_IDENTITY\n",
        "            )\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "        loop.set_postfix(H_real=TARGET_REALS/(idx+1), H_fake=TARGET_FAKES/(idx+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsZeVdWAT7jm"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKwOkFXMT9R0"
      },
      "outputs": [],
      "source": [
        "def main(config):\n",
        "    disc_target = Discriminator(in_channels=1).to(config.DEVICE)\n",
        "    disc_source = Discriminator(in_channels=1).to(config.DEVICE)\n",
        "    gen_source_target = Generator(channels=1, num_residuals=9).to(config.DEVICE)\n",
        "    gen_target_source = Generator(channels=1, num_residuals=9).to(config.DEVICE)\n",
        "\n",
        "    opt_disc = torch.optim.Adam(\n",
        "        list(disc_target.parameters()) + list(disc_source.parameters()),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = torch.optim.Adam(\n",
        "        list(gen_source_target.parameters()) + list(gen_target_source.parameters()),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    if config.LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            disc_target, opt_disc, config, config.CHECKPOINT_DISC_TARGET\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            disc_source, opt_disc, config, config.CHECKPOINT_TRG_SRC\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            gen_source_target, opt_gen, config, config.CHECKPOINT_GEN_TARGET\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            gen_target_source, opt_gen, config, config.CHECKPOINT_GEN_SRC\n",
        "        )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    dataset = Voice_Dataset(source_voice_path = config.SRC_VOICE_PATH,\n",
        "                  target_voice_path = config.TARGET_VOICE_PATH)\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=config.NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(config.CURRENT_EPOCH, config.NUM_EPOCHS):\n",
        "        print(\"epoch\", epoch)\n",
        "        train_fn(disc_target, disc_source, gen_source_target, gen_target_source, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler, config)\n",
        "        if epoch % 2 == 0 and epoch != 0:\n",
        "          save_checkpoint(disc_target, opt_disc, config, filename=os.path.join(config.MODELS_PATH, f'disc_target{epoch}.pth'))\n",
        "          save_checkpoint(disc_source, opt_disc, config, filename=os.path.join(config.MODELS_PATH, f'disc_source{epoch}.pth'))\n",
        "          save_checkpoint(gen_target_source, opt_gen, config, filename=os.path.join(config.MODELS_PATH, f'disc_gen_source{epoch}.pth'))\n",
        "          save_checkpoint(gen_source_target, opt_gen, config, filename=os.path.join(config.MODELS_PATH, f'disc_gen_source{epoch}.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWXspOb6gIcc"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "  def __init__(self):\n",
        "    self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    self.BATCH_SIZE = 1\n",
        "    self.LEARNING_RATE = 1e-5\n",
        "    self.LAMBDA_IDENTITY = 10.0\n",
        "    self.LAMBDA_CYCLE = 10\n",
        "    self.NUM_WORKERS = 1\n",
        "    self.NUM_EPOCHS = 1000\n",
        "    self.CURRENT_EPOCH = 0\n",
        "    self.LOAD_MODEL = True\n",
        "    self.CHECKPOINT_GEN_TARGET = \"/content/gdrive/MyDrive/test/gen_target10.pth\"\n",
        "    self.CHECKPOINT_GEN_SRC = \"/content/gdrive/MyDrive/test/gen_source10.pth\"\n",
        "    self.CHECKPOINT_DISC_TARGET = \"/content/gdrive/MyDrive/test/disc_target10.pth\"\n",
        "    self.CHECKPOINT_TRG_SRC = \"/content/gdrive/MyDrive/test/disc_source10.pth\"\n",
        "    self.SRC_VOICE_PATH = \"/content/gdrive/MyDrive/voice_data/voices_unzip/speaker4\"\n",
        "    self.TARGET_VOICE_PATH = \"/content/gdrive/MyDrive/voice_data/voices_unzip/speaker3\"\n",
        "    self.MODELS_PATH = \"/content/gdrive/MyDrive/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "9JYetrYDyTO5",
        "outputId": "f41f97fb-143c-44b5-b8a0-1cc726917ccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tak\n",
            "tak\n",
            "tak\n",
            "tak\n",
            "epoch 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/1132 [00:01<16:14,  1.16it/s, H_fake=0.463, H_real=0.467]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-53f82cf83ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-b19d36893940>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCURRENT_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_source_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_target_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODELS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'disc_target{epoch}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-051043dafcd7>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(disc_target, disc_source, gen_source_target, gen_target_source, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler, config)\u001b[0m\n\u001b[1;32m     67\u001b[0m             )\n\u001b[1;32m     68\u001b[0m         \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mg_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mg_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mg_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "conf = Config()\n",
        "main(conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL6p6igk69_7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "j1TD8IabTwJM",
        "NIbMIkMsTzYY",
        "-shMXZGyT3EM"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b239acf2821489c398a9848859e84ce39b99d30cc4031fb37cc7461da3883639"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
